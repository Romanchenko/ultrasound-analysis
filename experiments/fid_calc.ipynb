{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34374763-3746-4f71-a7bf-ac1c22a3fd12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:13:13.521535Z",
     "iopub.status.busy": "2026-02-08T14:13:13.520415Z",
     "iopub.status.idle": "2026-02-08T14:13:15.624501Z",
     "shell.execute_reply": "2026-02-08T14:13:15.623655Z",
     "shell.execute_reply.started": "2026-02-08T14:13:13.521493Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee9de73-7f72-4171-8416-2a604cede053",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:13:15.627111Z",
     "iopub.status.busy": "2026-02-08T14:13:15.625944Z",
     "iopub.status.idle": "2026-02-08T14:13:15.640814Z",
     "shell.execute_reply": "2026-02-08T14:13:15.640042Z",
     "shell.execute_reply.started": "2026-02-08T14:13:15.627070Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, str(pathlib.Path().resolve().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfabe7fb-dbed-484f-8d92-e0389fd0252f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:13:15.642443Z",
     "iopub.status.busy": "2026-02-08T14:13:15.641834Z",
     "iopub.status.idle": "2026-02-08T14:13:22.435784Z",
     "shell.execute_reply": "2026-02-08T14:13:22.434966Z",
     "shell.execute_reply.started": "2026-02-08T14:13:15.642409Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from domain_adaptation.cyclegan.dataloaders.base_dataloader import UnpairedDataset, create_dataloader\n",
    "from datasets_adapters.fetal_planes_db.fpd_dataset import FetalPlanesDBDataset\n",
    "from datasets_adapters.fetal_head_circ.fhc_dataset import FetalHeadCircDataset\n",
    "from quality.fid import calculate_fid_from_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eadae91-b9c2-4a8d-91a2-4f5558ea5d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:13:22.453386Z",
     "iopub.status.busy": "2026-02-08T14:13:22.451651Z",
     "iopub.status.idle": "2026-02-08T14:13:22.472132Z",
     "shell.execute_reply": "2026-02-08T14:13:22.471225Z",
     "shell.execute_reply.started": "2026-02-08T14:13:22.453347Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6776cd95-0ef5-45ec-b723-79a6bd72f509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:13:22.474289Z",
     "iopub.status.busy": "2026-02-08T14:13:22.473418Z",
     "iopub.status.idle": "2026-02-08T14:13:26.998911Z",
     "shell.execute_reply": "2026-02-08T14:13:26.998207Z",
     "shell.execute_reply.started": "2026-02-08T14:13:22.474251Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12400 images from /home/jupyter/datasphere/project/ultrasound/datasetss/fetal_planes_db\n",
      "Loaded 999 images from /home/jupyter/datasphere/project/ultrasound/datasetss/fetal_head_circumference/training_set\n",
      "Found 999 annotation images\n"
     ]
    }
   ],
   "source": [
    "dataset_a = FetalPlanesDBDataset(\n",
    "    root = '/home/jupyter/datasphere/project/ultrasound/datasetss/fetal_planes_db',\n",
    "    transform = None,\n",
    "    target_size = (224, 224),\n",
    "    csv_file = 'FETAL_PLANES_DB_data.csv',\n",
    "    images_dir = 'Images',\n",
    "    train = None,\n",
    ")\n",
    "\n",
    "dataset_b = FetalHeadCircDataset(\n",
    "    images_dir = '/home/jupyter/datasphere/project/ultrasound/datasetss/fetal_head_circumference/training_set',\n",
    "    csv_file = '/home/jupyter/datasphere/project/ultrasound/datasetss/fetal_head_circumference/training_set_pixel_size_and_HC.csv',\n",
    "    transform = None,\n",
    "    target_size = (224, 224),\n",
    "    load_annotations = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f94b61a-2a23-4256-b393-1608aa285655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T13:07:54.448058Z",
     "iopub.status.busy": "2026-02-08T13:07:54.447595Z",
     "iopub.status.idle": "2026-02-08T13:08:41.834970Z",
     "shell.execute_reply": "2026-02-08T13:08:41.833868Z",
     "shell.execute_reply.started": "2026-02-08T13:07:54.448033Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating FID between two datasets...\n",
      "Dataset 1: 12400 samples\n",
      "Dataset 2: 999 samples\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /tmp/xdg_cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97.8M/97.8M [00:01<00:00, 55.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting features from dataset 1...\n",
      "Using device: cuda\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 388/388 [00:35<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 12400 features of dimension 2048\n",
      "\n",
      "Extracting features from dataset 2...\n",
      "Using device: cuda\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 32/32 [00:03<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 999 features of dimension 2048\n",
      "\n",
      "Calculating FID score...\n"
     ]
    }
   ],
   "source": [
    "initial_fid_score = calculate_fid_from_datasets(dataset_a, dataset_b, device=device, image_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70565e11-abad-4dcf-83ac-3a900ec7bf4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T13:08:41.838193Z",
     "iopub.status.busy": "2026-02-08T13:08:41.837137Z",
     "iopub.status.idle": "2026-02-08T13:08:41.849986Z",
     "shell.execute_reply": "2026-02-08T13:08:41.849143Z",
     "shell.execute_reply.started": "2026-02-08T13:08:41.838154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_fid_score: 67.1516130298318\n"
     ]
    }
   ],
   "source": [
    "print(f'initial_fid_score: {initial_fid_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85bae7c7-cb6c-487e-b268-372b54ae5398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:13:27.725568Z",
     "iopub.status.busy": "2026-02-08T14:13:27.724714Z",
     "iopub.status.idle": "2026-02-08T14:13:27.745345Z",
     "shell.execute_reply": "2026-02-08T14:13:27.744638Z",
     "shell.execute_reply.started": "2026-02-08T14:13:27.725541Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from domain_adaptation.cyclegan.train import CycleGANTrainer\n",
    "from domain_adaptation.cyclegan.model import CycleGAN\n",
    "from domain_adaptation.cyclegan.dataloaders.translated_dataset import CycleGANTranslatedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "783599ca-8ce4-4624-b6fd-5d07b4b61918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T12:34:42.682420Z",
     "iopub.status.busy": "2026-02-08T12:34:42.681856Z",
     "iopub.status.idle": "2026-02-08T12:34:42.699216Z",
     "shell.execute_reply": "2026-02-08T12:34:42.698561Z",
     "shell.execute_reply.started": "2026-02-08T12:34:42.682393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model.pt\n",
      "checkpoint_epoch_1.pt\n",
      "checkpoint_epoch_10.pt\n",
      "checkpoint_epoch_12.pt\n",
      "checkpoint_epoch_13.pt\n",
      "checkpoint_epoch_14.pt\n",
      "checkpoint_epoch_16.pt\n",
      "checkpoint_epoch_18.pt\n",
      "checkpoint_epoch_19.pt\n",
      "checkpoint_epoch_2.pt\n",
      "checkpoint_epoch_20.pt\n",
      "checkpoint_epoch_3.pt\n",
      "checkpoint_epoch_4.pt\n",
      "checkpoint_epoch_6.pt\n",
      "checkpoint_epoch_8.pt\n",
      "samples\n"
     ]
    }
   ],
   "source": [
    "!ls ./checkpoints/cyclegan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc67554f-1fd6-4749-8152-79afa341b433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:13:34.016417Z",
     "iopub.status.busy": "2026-02-08T14:13:34.015564Z",
     "iopub.status.idle": "2026-02-08T14:13:34.254977Z",
     "shell.execute_reply": "2026-02-08T14:13:34.254251Z",
     "shell.execute_reply.started": "2026-02-08T14:13:34.016389Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load cyclegan\n",
    "model = CycleGAN(\n",
    "    input_channels_a = 1,\n",
    "    input_channels_b = 1,\n",
    "    n_residual_blocks = 3,\n",
    ")\n",
    "trainer = CycleGANTrainer(\n",
    "    model=model,\n",
    "    device=torch.device('cpu'),\n",
    "    lambda_cycle=10,\n",
    "    lambda_identity=0.5,\n",
    "    lr_g=2e-4,\n",
    "    lr_d=2e-4\n",
    ")\n",
    "checkpoint = trainer.load_checkpoint('./checkpoints/cyclegan/best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef8812e6-52ac-473e-a07b-9fc1563abfc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T13:39:39.928826Z",
     "iopub.status.busy": "2026-02-08T13:39:39.927662Z",
     "iopub.status.idle": "2026-02-08T13:39:39.958838Z",
     "shell.execute_reply": "2026-02-08T13:39:39.957997Z",
     "shell.execute_reply.started": "2026-02-08T13:39:39.928784Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_a_to_b = CycleGANTranslatedDataset(\n",
    "    cyclegan_model = model,\n",
    "    source_dataset = dataset_a,\n",
    "    device = torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02b5a4b3-3233-4d55-9817-1eaafaf16bcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T13:39:41.107668Z",
     "iopub.status.busy": "2026-02-08T13:39:41.106768Z",
     "iopub.status.idle": "2026-02-08T14:00:59.460993Z",
     "shell.execute_reply": "2026-02-08T14:00:59.459727Z",
     "shell.execute_reply.started": "2026-02-08T13:39:41.107629Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating FID between two datasets...\n",
      "Dataset 1: 12400 samples\n",
      "Dataset 2: 999 samples\n",
      "\n",
      "Extracting features from dataset 1...\n",
      "Using device: cuda\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 388/388 [21:08<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 12400 features of dimension 2048\n",
      "\n",
      "Extracting features from dataset 2...\n",
      "Using device: cuda\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 32/32 [00:04<00:00,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 999 features of dimension 2048\n",
      "\n",
      "Calculating FID score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a_to_b_fid_score = calculate_fid_from_datasets(dataset_a_to_b, dataset_b, device=device, image_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7c092d2-749a-475e-b58f-473fb3925f96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:03:41.609632Z",
     "iopub.status.busy": "2026-02-08T14:03:41.608678Z",
     "iopub.status.idle": "2026-02-08T14:03:41.622606Z",
     "shell.execute_reply": "2026-02-08T14:03:41.621901Z",
     "shell.execute_reply.started": "2026-02-08T14:03:41.609591Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_to_b_fid_score: 46.15082634065115\n"
     ]
    }
   ],
   "source": [
    "print(f'a_to_b_fid_score: {a_to_b_fid_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2e21e2b-e438-46d5-931f-12be017c752d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:13:46.246247Z",
     "iopub.status.busy": "2026-02-08T14:13:46.245333Z",
     "iopub.status.idle": "2026-02-08T14:13:46.255985Z",
     "shell.execute_reply": "2026-02-08T14:13:46.255369Z",
     "shell.execute_reply.started": "2026-02-08T14:13:46.246200Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_b_to_a = CycleGANTranslatedDataset(\n",
    "    cyclegan_model = model,\n",
    "    source_dataset = dataset_b,\n",
    "    device = torch.device('cpu'),\n",
    "    b2a = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b9311c8-8d0f-4c80-9292-6b36722dc5a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:14:34.741963Z",
     "iopub.status.busy": "2026-02-08T14:14:34.741009Z",
     "iopub.status.idle": "2026-02-08T14:17:15.626335Z",
     "shell.execute_reply": "2026-02-08T14:17:15.625097Z",
     "shell.execute_reply.started": "2026-02-08T14:14:34.741912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating FID between two datasets...\n",
      "Dataset 1: 12400 samples\n",
      "Dataset 2: 999 samples\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /tmp/xdg_cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97.8M/97.8M [00:02<00:00, 41.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting features from dataset 1...\n",
      "Using device: cuda\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 388/388 [00:37<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 12400 features of dimension 2048\n",
      "\n",
      "Extracting features from dataset 2...\n",
      "Using device: cuda\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 32/32 [01:55<00:00,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 999 features of dimension 2048\n",
      "\n",
      "Calculating FID score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "b_to_a_fid_score = calculate_fid_from_datasets(dataset_a, dataset_b_to_a, device=device, image_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3378300-b3c1-4087-b832-640365aae27d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:18:25.747730Z",
     "iopub.status.busy": "2026-02-08T14:18:25.746755Z",
     "iopub.status.idle": "2026-02-08T14:18:25.759747Z",
     "shell.execute_reply": "2026-02-08T14:18:25.759123Z",
     "shell.execute_reply.started": "2026-02-08T14:18:25.747684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_to_a_fid_score: 81.69116442403748\n"
     ]
    }
   ],
   "source": [
    "print(f'b_to_a_fid_score: {b_to_a_fid_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa16a538-33e9-4605-a338-d418adbbe9f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:47:29.457685Z",
     "iopub.status.busy": "2026-02-08T14:47:29.456782Z",
     "iopub.status.idle": "2026-02-08T14:47:29.480913Z",
     "shell.execute_reply": "2026-02-08T14:47:29.480184Z",
     "shell.execute_reply.started": "2026-02-08T14:47:29.457654Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets_adapters.dogs.dogs_dataset import DogsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c41683c5-6cf1-4391-b73d-2fb58ffd66b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:48:14.288480Z",
     "iopub.status.busy": "2026-02-08T14:48:14.287968Z",
     "iopub.status.idle": "2026-02-08T14:48:14.316419Z",
     "shell.execute_reply": "2026-02-08T14:48:14.315796Z",
     "shell.execute_reply.started": "2026-02-08T14:48:14.288438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 494 images across 4 breeds from /home/jupyter/datasphere/project/ultrasound/datasetss/dogs_dataset\n"
     ]
    }
   ],
   "source": [
    "doggies = DogsDataset(\n",
    "    root='/home/jupyter/datasphere/project/ultrasound/datasetss/dogs_dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62059340-8b15-4697-968b-aafc3fb828eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:48:48.567662Z",
     "iopub.status.busy": "2026-02-08T14:48:48.566799Z",
     "iopub.status.idle": "2026-02-08T14:49:41.981003Z",
     "shell.execute_reply": "2026-02-08T14:49:41.979904Z",
     "shell.execute_reply.started": "2026-02-08T14:48:48.567634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating FID between two datasets...\n",
      "Dataset 1: 12400 samples\n",
      "Dataset 2: 494 samples\n",
      "\n",
      "Extracting features from dataset 1...\n",
      "Using device: cuda\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 388/388 [00:36<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 12400 features of dimension 2048\n",
      "\n",
      "Extracting features from dataset 2...\n",
      "Using device: cuda\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  62%|██████▎   | 10/16 [00:05<00:02,  2.24it/s]/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Processing batches: 100%|██████████| 16/16 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 494 features of dimension 2048\n",
      "\n",
      "Calculating FID score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a_to_dog_fid = calculate_fid_from_datasets(dataset_a, doggies, device=device, image_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9fd6bba-1ec7-42a9-84cd-44fae419d70b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:50:38.120675Z",
     "iopub.status.busy": "2026-02-08T14:50:38.119803Z",
     "iopub.status.idle": "2026-02-08T14:50:38.138005Z",
     "shell.execute_reply": "2026-02-08T14:50:38.137332Z",
     "shell.execute_reply.started": "2026-02-08T14:50:38.120639Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_to_dog_fid: 241.54387621118366\n"
     ]
    }
   ],
   "source": [
    "print(f'a_to_dog_fid: {a_to_dog_fid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df786811-6061-465d-af6a-e0760729437d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:50:52.406032Z",
     "iopub.status.busy": "2026-02-08T14:50:52.404752Z",
     "iopub.status.idle": "2026-02-08T14:51:12.171879Z",
     "shell.execute_reply": "2026-02-08T14:51:12.170741Z",
     "shell.execute_reply.started": "2026-02-08T14:50:52.406002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating FID between two datasets...\n",
      "Dataset 1: 999 samples\n",
      "Dataset 2: 494 samples\n",
      "\n",
      "Extracting features from dataset 1...\n",
      "Using device: cuda\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 32/32 [00:05<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 999 features of dimension 2048\n",
      "\n",
      "Extracting features from dataset 2...\n",
      "Using device: cuda\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  62%|██████▎   | 10/16 [00:05<00:02,  2.48it/s]/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Processing batches: 100%|██████████| 16/16 [00:09<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 494 features of dimension 2048\n",
      "\n",
      "Calculating FID score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "b_to_dog_fid = calculate_fid_from_datasets(dataset_b, doggies, device=device, image_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9221440b-bb6e-4f1d-b6e7-14f074aeb83c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T14:51:24.303841Z",
     "iopub.status.busy": "2026-02-08T14:51:24.302986Z",
     "iopub.status.idle": "2026-02-08T14:51:24.313366Z",
     "shell.execute_reply": "2026-02-08T14:51:24.312765Z",
     "shell.execute_reply.started": "2026-02-08T14:51:24.303802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_to_dog_fid: 244.2196451284496\n"
     ]
    }
   ],
   "source": [
    "print(f'b_to_dog_fid: {b_to_dog_fid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a75eb89-2b7d-4d44-95ba-6f6e60986b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
